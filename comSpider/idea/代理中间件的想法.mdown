##　代理中间件的想法
> 代理的使用无非就是怎么取，怎么用，用后怎么保存的问题，取可以另外写接口，存大部分时间都不需要，所以关键还是在于怎么用 (￣▽￣)／
### 代理的使用规则
#### 代理的使用面对的问题
- 如果一个代理IP使用过快，就可能面对被封的问题，影响使用效果 （具体就是单个IP访问间隔）
- 如果一个IP失效，如何最快的发现失效IP，并让其出队 （涉及到返回错误的判断，是被ban了，还是不可用，还是网络问题等等）
- 单机和多机问题，代理池通过master进行派发并不好，最好的方法还是初始化时根据各slaver具体情况（线程数、网络情况等），分发给slaver不重复的固定个数代理，之后就让slaver固定用这些代理来跑。
#### 代理规则构想
- 使用一个IP上次请求时间作为一个判断关键字，如果IP对某网站上次访问时间距离现在时间超过一定时间，则可用，防止被ban，但是怎么柱塞？不会 /(ㄒoㄒ)/~~
- IP出入队规则，代理可使用LIFO队列进行保存，每个IP有个权值代表其好不好用，每请求成功一次，可提升权值，失败一次，降低权值，权值小于一个定值则出队。
### 代理池的编写
- 先写单机的 (￣▽￣)~*
- 存取接口另外写（可以写成设置文件，配置入口，自动识别）,接口可以支持分布式派发。
- 下载延迟的编写，想了很久，多IP无法设置download_delay_for_each_ip,但是应该可以根据并行的IP数来更改download_delay，比如20个可用IP，站点接受频率是5s一次，就可以设置delay在0.3s左右。这样slaver部署的时候注意点，设置下就好了，单机就根据一个可用IP数大概设置下就行了，跑的途中可用IP也在变，临时改变还要改写from_crawler方法，太麻烦 ╮(╯﹏╰）╭。
- scrapy下载delay相关代码在 scrapy/core/downloader/\_\_init\_\_.py
